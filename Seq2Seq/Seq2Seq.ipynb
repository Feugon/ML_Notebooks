{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924c6cf0",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "In this project we will attempt to implement a basic Seq2Seq model architecture and train it to create transliterations from Russian to English. A transliteration is a form of translation where we aim to keep the pronunciation aspect across the two languages, rather than keeping the semantic meaning.  \n",
    "\n",
    "### Import Libraries\n",
    "\n",
    "We start this project by importing the common libraries that will be used throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfac8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13100a4c",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset for this project was found on [Kaggle](https://www.kaggle.com/datasets/colesuoseue/2m-rus2eng-transliterated?resource=download). It contains 2.3 million examples of Russian to English transliterations, as well as weights that represent how common a transliteration is. Our file is in a .parquet format, which stores column-wise rather than row-wise. Overall, this doesn't impact our process in any way but is something to note.\n",
    "\n",
    "We start by reading the data into a pandas table and taking a look at some of its samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ed56e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  original_word transliteration  weight\n",
      "0            аа              aa     1.0\n",
      "1           ааа             aaa     1.0\n",
      "2        аагатэ          aagate     1.0\n",
      "3        аагатэ          aahate     0.3\n",
      "4        аагатэ         aagathe     0.5\n",
      "2314084\n"
     ]
    }
   ],
   "source": [
    "db = pd.read_parquet(\"rus_to_en_data.parquet\")\n",
    "print(db.head())\n",
    "print(len(db))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb2cce7",
   "metadata": {},
   "source": [
    "Everything works! As we can see the original_word is the Russian word and the transliteration is the phonetic representation of it in English. Also note the weights of the transliteration. They represent how common a transliteration is and are marked on a scale of 0-1 but that does not mean that the different transliterations of the same word will sum up to 1.\n",
    "\n",
    "Next, we want to make sure to standardize the way the Russian letters get represented in Unicode. We do this via NFC normalization which makes sure we always refer to the dedicated Unicode of the character instead of the alternative where it uses a combination of Unicodes. For example the letter ё could be converted to its own unicode or it could be a combination of a unicode for e and a unicode for the two dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856774ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "db[\"original_word\"] = db[\"original_word\"].apply(lambda x: unicodedata.normalize(\"NFC\", x.lower()))\n",
    "db[\"transliteration\"] = db[\"transliteration\"].apply(lambda x: unicodedata.normalize(\"NFC\", x.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b8f993",
   "metadata": {},
   "source": [
    "Now we will create our vocabulary for the two sequences. Since we are dealing with phonetic pronunciations of words it makes sense that our tokens will be just single letters. In order to get this vocab we will get a list of all the unique letters used in our data for each language. \n",
    "\n",
    "We will also add tokens that will help us train and infer the model:\n",
    "- The &lt;pad&gt; token is used to make sure that all of the input strings in the same batch are of the same length, otherwise the encoder would not be able to work\n",
    "- The &lt;bos&gt; token stands for \"beginning of sentence\" which is necessary for teacher forcing (more on that later)\n",
    "- The &lt;eos&gt; token stands for \"end of sentence\" and is used to end the decoding process\n",
    "- The &lt;unk&gt; token is for any unknown tokens that the model might see. For our case it is likely unnecessary, but it makes the usage of our model more robust\n",
    "\n",
    "And we will also define string-to-index and index-to-string dictionaries that will be used for our encode and decode functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a09834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocab Size: 25\n",
      "Russian Vocab Size: 33\n",
      "a 4\n",
      "а 4\n"
     ]
    }
   ],
   "source": [
    "russian_vocab = list(set(\"\".join(db[\"original_word\"])))\n",
    "english_vocab = list(set(\"\".join(db[\"transliteration\"])))\n",
    "\n",
    "print(f\"English Vocab Size: {len(english_vocab)}\")\n",
    "print(f\"Russian Vocab Size: {len(russian_vocab)}\")\n",
    "\n",
    "russian_vocab = [\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"] + sorted(russian_vocab)\n",
    "english_vocab = [\"<pad>\", \"<bos>\", \"<eos>\", \"<unk>\"] + sorted(english_vocab)\n",
    "PAD_ID = 0; BOS_ID = 1; EOS_ID = 2; UNK_ID = 3\n",
    "\n",
    "# stoi = string to index, itos = index to string\n",
    "russian_stoi = {char: idx for idx, char in enumerate(russian_vocab)}\n",
    "russian_itos = {idx: char for char, idx in russian_stoi.items()}\n",
    "english_stoi = {char: idx for idx, char in enumerate(english_vocab)}\n",
    "english_itos = {idx: char for char, idx in english_stoi.items()}\n",
    "\n",
    "# sanity check\n",
    "print(english_itos[4], english_stoi[\"a\"])\n",
    "print(russian_itos[4], russian_stoi[\"а\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb83f47",
   "metadata": {},
   "source": [
    "This is a bit of a surprise. Our English vocab is only 25 letters while there are 26 letters in the Latin alphabet. Taking a closer look you can see that the letter *q* is missing from the list of unique characters. If you speak Russian this might not be so surprising to you, it is a sound that is unlike any of the Russian pronunciations. When first thinking about how to set the vocab lengths I thought to just set them to the respective alphabet lengths. Now we can see why that would have been slightly inaccurate to do.\n",
    "\n",
    "Next, we will create our encode function that will convert the string of characters into a vector of character IDs and the decode function that would undo that change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f46f8d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 19, 20, 12, 6, 9, 22, 2]\n",
      "<bos>привет<eos>\n"
     ]
    }
   ],
   "source": [
    "def encode(text, stoi):\n",
    "    tokenized = [stoi[\"<bos>\"]] + [stoi.get(char, stoi[\"<unk>\"]) for char in text] + [stoi[\"<eos>\"]]\n",
    "    return tokenized\n",
    "\n",
    "def decode(tokens, itos):\n",
    "    return \"\".join([itos.get(token, \"<unk>\") for token in tokens if itos[token] != \"<pad>\"])\n",
    "\n",
    "print(encode(\"привет\", russian_stoi))  \n",
    "print(decode([1, 19, 20, 12, 6, 9, 22, 2], russian_itos))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5542fccd",
   "metadata": {},
   "source": [
    "Nice and easy. Next is a train/val/test split of our data. There is an important nuance that we have to be aware of to not mess up our training. There are duplicate words in the dataset with different weights. To avoid having some of the train words in the test set we make sure that all the duplicates stay in the same split. We also shuffle the data to prevent the model from learning the order of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146470f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  original_word transliteration  weight\n",
      "0  обговоренный   obhouoryennyy    0.09\n",
      "1      очернять      ochyernyat    0.70\n",
      "2      фатализм       fathalizm    0.50\n",
      "3   гандбольный      handbolnii    0.19\n",
      "4    задушенный    zaduschennyy    0.29\n",
      "Train size: 1849957, Validation size: 231823, Test size: 232304\n"
     ]
    }
   ],
   "source": [
    "db = db.sample(frac=1,random_state=123).reset_index(drop=True)\n",
    "print(db.head())\n",
    "\n",
    "uniq_src = db[\"original_word\"].drop_duplicates().sample(frac=1, random_state=123).tolist()\n",
    "\n",
    "n = len(uniq_src)\n",
    "n_train = int(n * 0.8)\n",
    "n_val   = int(n * 0.1)\n",
    "train_src = set(uniq_src[:n_train])\n",
    "val_src   = set(uniq_src[n_train:n_train+n_val])\n",
    "test_src  = set(uniq_src[n_train+n_val:])\n",
    "\n",
    "train_data = db[db[\"original_word\"].isin(train_src)].reset_index(drop=True)\n",
    "val_data   = db[db[\"original_word\"].isin(val_src)].reset_index(drop=True)\n",
    "test_data  = db[db[\"original_word\"].isin(test_src)].reset_index(drop=True)\n",
    "\n",
    "print(f\"Train size: {len(train_data)}, Validation size: {len(val_data)}, Test size: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a839dc",
   "metadata": {},
   "source": [
    "Now we get to creating a `DataLoader` class. Before that, we need to create a `Dataset` class, which is rather simple. The only note I have about this process is that we do encode the words and convert the resulting vectors into tensors.\n",
    "\n",
    "Here come the nuances that you don't learn from reading the textbook. Although the overall architecture of a Seq2Seq model is flexible with the amount of time steps in a sequence, or in our case letters in a word, they don't behave as nicely with batches of variable input lengths. The layers that we will utilize for our model all expect box-shaped tensors, but if some input words are longer than others then we might not have that. That is why we introduced the `<pad>` token. This allows us to pad the batches to make sure that all vectors are of the same length. In order to implement this feature we use a collate function, which are functions that handle how to format the batches cleanly. Fortunately for us PyTorch has a function to handle the padding for us and we don't need to sweat over the implementation details.\n",
    "\n",
    "After we define the collate function we can finally create our `DataLoader` class and get a step closer to training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34896405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class s2sDataset(Dataset):\n",
    "    def __init__(self,db, rus_stoi, eng_stoi):\n",
    "        self.db = db\n",
    "        self.rus_stoi = rus_stoi\n",
    "        self.eng_stoi = eng_stoi\n",
    "        self.rus = db[\"original_word\"].tolist()\n",
    "        self.eng = db[\"transliteration\"].tolist()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.db)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rus_text = self.rus[idx]\n",
    "        eng_text = self.eng[idx]\n",
    "        \n",
    "        rus_encoded = encode(rus_text, self.rus_stoi)\n",
    "        eng_encoded = encode(eng_text, self.eng_stoi)\n",
    "\n",
    "        return {\n",
    "            \"rus\": torch.tensor(rus_encoded, dtype=torch.long),\n",
    "            \"eng\": torch.tensor(eng_encoded, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def make_collate_fn(PAD_ID = 0):\n",
    "    def collate_fn(batch):\n",
    "        rus_batch = [item[\"rus\"] for item in batch]\n",
    "        eng_batch = [item[\"eng\"] for item in batch]\n",
    "        \n",
    "        rus_padded = nn.utils.rnn.pad_sequence(rus_batch, batch_first=True, padding_value=PAD_ID)\n",
    "        eng_padded = nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=PAD_ID)\n",
    "        # compute true lengths (exclude padding)\n",
    "        src_len = (rus_padded != PAD_ID).sum(dim=1)\n",
    "        return {\n",
    "            \"rus\": rus_padded,\n",
    "            \"eng\": eng_padded,\n",
    "            \"src_len\": src_len\n",
    "        }\n",
    "    \n",
    "    return collate_fn\n",
    "\n",
    "train_dataset = s2sDataset(train_data, russian_stoi, english_stoi)\n",
    "val_dataset = s2sDataset(val_data, russian_stoi, english_stoi)\n",
    "test_dataset = s2sDataset(test_data, russian_stoi, english_stoi)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True,  collate_fn=make_collate_fn(PAD_ID))\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=256, shuffle=False, collate_fn=make_collate_fn(PAD_ID))\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=256, shuffle=False, collate_fn=make_collate_fn(PAD_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5f6a17",
   "metadata": {},
   "source": [
    "Let's see some examples of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38c8b96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 18]) torch.Size([256, 23])\n",
      "tensor([ 1, 23, 17, 12,  6,  9, 20, 21,  4, 15,  2,  0,  0,  0,  0,  0,  0,  0]) tensor([ 1, 23, 17, 12, 23,  8, 20, 21,  4, 15,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0])\n",
      "<bos>универсал<eos>\n",
      "<bos>uniuersal<eos>\n"
     ]
    }
   ],
   "source": [
    "batch_example = next(iter(train_loader))\n",
    "print(batch_example[\"rus\"].shape, batch_example[\"eng\"].shape)\n",
    "print(batch_example[\"rus\"][0], batch_example[\"eng\"][0])\n",
    "print(decode(batch_example[\"rus\"][0].tolist(), russian_itos))\n",
    "print(decode(batch_example[\"eng\"][0].tolist(), english_itos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3ae90",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "We are now ready to create our model! For this task we will use a rather bare-bones version of Seq2Seq. For this project we will aim for a mix of simplicity and performance. This is partly because of my resource constraints in terms of compute power and because this notebook is meant to be a semi-educational guide on how these models work rather than a tutorial for creating the best transliteration model possible. \n",
    "\n",
    "Here are the details of the model architecture:\n",
    "- Two embedding layers since we have two different vocabularies, we also use a `padding_idx` parameter so the `<pad>` token never influences any of the gradients\n",
    "- We use a basic encoder-decoder design \n",
    "    - Both of them use GRUs, a form of RNNs that help with vanishing gradient issues that RNNs are notorious for\n",
    "- Our output layer is a linear layer that takes the hidden state of the decoder and converts it to logits that determine which letter is the most likely to appear next\n",
    "- We shift the target sequence one to the right in order to facilitate training\n",
    "- We use a simple dot-product cross attention mechanism. This is not needed for our task because the only relevant context are the letters around the current one, but I thought it would be educational to implement it as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5296f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, emb_dim, hidden_dim, padding_idx=0, n_layers=1):\n",
    "        super(Seq2SeqModel, self).__init__()\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, emb_dim, padding_idx=padding_idx)\n",
    "        self.trg_embedding = nn.Embedding(trg_vocab_size, emb_dim, padding_idx=padding_idx)\n",
    "        self.encoder = nn.GRU(emb_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.decoder = nn.GRU(emb_dim, hidden_dim, n_layers, batch_first=True)\n",
    "        self.output  = nn.Linear(hidden_dim, trg_vocab_size)\n",
    "        self.pad_id  = padding_idx \n",
    "\n",
    "    def forward(self, src, trg, src_len):\n",
    "        src_emb = self.src_embedding(src)                    \n",
    "        packed = pack_padded_sequence(src_emb, src_len.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        enc_out_packed, enc_last_hidden = self.encoder(packed)\n",
    "        enc_out, _ = pad_packed_sequence(enc_out_packed, batch_first=True)  \n",
    "\n",
    "        trg_emb = self.trg_embedding(trg[:, :-1])            \n",
    "        dec_output, _ = self.decoder(trg_emb, enc_last_hidden)  \n",
    "\n",
    "        logits = self.output(dec_output)                     \n",
    "        return logits, enc_out, enc_last_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4034f24",
   "metadata": {},
   "source": [
    "### Training\n",
    "Now we can define our training function. There are some nuances with padding, which as I learned through this project is a common thing for NLP training, but fortunately for us PyTorch abstracts most of these issues     away. \n",
    "\n",
    "We do a little extra work here to represent the loss in the best way possible and I'll explain how. The `CrossEntropyLoss` function does return the average token loss per batch which excludes any padding. But each batch could have a different total amount of tokens in them which would make our loss be a tad innacurate of a representation. For example, if we had two batches and their respective token amounts were 100 and 50 using the pure score from `CrossEntropyLoss` would just result in an unweighted average. What we do in the loop is make sure to scale the batch weights accordingly to the amount of tokens in them.\n",
    "\n",
    "We also utilized a validation set here to monitor the bias-variance tradeoffs and label smoothing to prevent overffiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bbbc7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, pad_id, optimizer, device, num_epochs=10):\n",
    "\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_id, label_smoothing=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # -------- training loop --------\n",
    "        model.train()\n",
    "        token_loss_sum, token_count = 0.0, 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            src = batch[\"rus\"].to(device)\n",
    "            trg = batch[\"eng\"].to(device)\n",
    "            src_len = batch[\"src_len\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits, _, _ = model(src, trg, src_len=src_len)\n",
    "            loss = criterion(\n",
    "                logits.view(-1, logits.size(-1)),\n",
    "                trg[:, 1:].reshape(-1)\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                valid = (trg[:, 1:] != pad_id).sum().item()\n",
    "                token_loss_sum += loss.item() * valid\n",
    "                token_count += valid\n",
    "\n",
    "        avg_token_loss = token_loss_sum / max(1, token_count)\n",
    "        train_loss_history.append(avg_token_loss)\n",
    "\n",
    "        # -------- validation loop --------\n",
    "        model.eval()\n",
    "        val_loss_sum, val_token_count = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                src = batch[\"rus\"].to(device)\n",
    "                trg = batch[\"eng\"].to(device)\n",
    "                src_len = batch[\"src_len\"].to(device)\n",
    "\n",
    "                logits, _, _ = model(src, trg, src_len=src_len)\n",
    "                val_loss = criterion(\n",
    "                    logits.view(-1, logits.size(-1)),\n",
    "                    trg[:, 1:].reshape(-1)\n",
    "                )\n",
    "                valid = (trg[:, 1:] != pad_id).sum().item()\n",
    "                val_loss_sum += val_loss.item() * valid\n",
    "                val_token_count += valid\n",
    "\n",
    "        avg_val_loss = val_loss_sum / max(1, val_token_count)\n",
    "        val_loss_history.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"train_loss={avg_token_loss:.4f}, \"\n",
    "              f\"val_loss={avg_val_loss:.4f}\")\n",
    "\n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237aabc",
   "metadata": {},
   "source": [
    "### Inference/Decoding\n",
    "\n",
    "Our model learns the probabilities of the next tokens given the currently selected one, we can express this as $p(x_T | x_{t < T})$ where $x_T$ is the token we are trying to generate. Given these probabilities we need to select tokens until we hit an `<eos>` one. There are multiple ways to do this, one of the most common one being beam search, but for our case greedy decoding seems adequate.\n",
    "\n",
    "Greedy decoding is where we simply choose the most likely token at every step of the way and add it to our output. This does not necessarily produce the most likely sequence. We could have a scenario where the most likely sequence actually starts with the second most likely token but because it \"flows\" better with the next tokens the entire sequence is actually a more probable sample compared to any greedy-based algorithms. However, for our purposes the transliterations from a Russian letter to an English one is close to a one-to-one mapping in most scenarios and therefore picking the most probable transliteration is often good enough. Also this is by far the fastest algorithm, the prominent beam search is about *k* times slower where *k* is the number of paths we keep at each timestep.\n",
    "\n",
    "As a side note, I did try using beam search and found that the difference in the metric that we use to judge our model was about 0.4% in favor of beam search, but it was significantly slower as we predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def greedy_decode(model, src, bos_id, eos_id, device, max_length=20, src_len=None):\n",
    "    model.eval()\n",
    "    pad_id = getattr(model, \"pad_id\", 0)\n",
    "\n",
    "    src = src.to(device)\n",
    "    if src_len is None:\n",
    "        src_len = (src != pad_id).sum(dim=1)\n",
    "\n",
    "    src_emb = model.src_embedding(src)\n",
    "    packed = pack_padded_sequence(src_emb, src_len.cpu(), batch_first=True, enforce_sorted=False)\n",
    "    enc_out_packed, enc_last_hidden = model.encoder(packed)\n",
    "    enc_out, _ = pad_packed_sequence(enc_out_packed, batch_first=True)  \n",
    "\n",
    "    batch_size = src.size(0)\n",
    "    trg_input = torch.full((batch_size, 1), bos_id, dtype=torch.long, device=device)\n",
    "    trg_output = [] \n",
    "\n",
    "    dec_hidden = enc_last_hidden\n",
    "    finished = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        trg_emb = model.trg_embedding(trg_input)              \n",
    "        dec_out, dec_hidden = model.decoder(trg_emb, dec_hidden)  \n",
    "\n",
    "        scores = torch.bmm(dec_out, enc_out.transpose(1, 2))\n",
    "        if pad_id is not None:\n",
    "            enc_pad_mask = (src == pad_id).unsqueeze(1)       \n",
    "            scores = scores.masked_fill(enc_pad_mask, -1e9)\n",
    "        attn_weights = F.softmax(scores, dim=-1)              \n",
    "        context = torch.bmm(attn_weights, enc_out)            \n",
    "        logits = model.output(dec_out)                        \n",
    "\n",
    "        next_token = logits.argmax(dim=-1)                    \n",
    "        trg_output.append(next_token)\n",
    "\n",
    "        finished = finished | (next_token.squeeze(1) == eos_id)\n",
    "        next_token = torch.where(\n",
    "            finished.unsqueeze(1),\n",
    "            torch.full_like(next_token, eos_id),\n",
    "            next_token\n",
    "        )\n",
    "        trg_input = next_token\n",
    "\n",
    "        if finished.all():\n",
    "            break\n",
    "\n",
    "    return torch.cat(trg_output, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5980e829",
   "metadata": {},
   "source": [
    "### Evals\n",
    "\n",
    "We will use something called character error rate. This uses edit distance (also known as Levenshtein distance) to calculate how far off two strings are. It assigns 1 point to every change we need to make in order to make the two strings identical; a change can be change of letters, insertion, and deletion. The distance alone doesn't tell us much, but if we express it as a percentage relative to the entire string lengths we can get an estimate of what percentage of characters need edits, lower is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddcdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.text import edit_distance\n",
    "\n",
    "def character_error_rate(preds, targets, itos, pad_id, bos_id, eos_id):\n",
    "    def to_str(seq):\n",
    "        chars = []\n",
    "        for t in seq:\n",
    "            if t in (pad_id, bos_id):\n",
    "                continue\n",
    "            if t == eos_id:\n",
    "                break\n",
    "            chars.append(itos[t])\n",
    "        return \"\".join(chars)\n",
    "\n",
    "    pred_strs   = [to_str(p) for p in preds]\n",
    "    target_strs = [to_str(t) for t in targets]\n",
    "\n",
    "    total_cer, total_count = 0.0, 0\n",
    "    for p, g in zip(pred_strs, target_strs):\n",
    "        dist = edit_distance(p, g)\n",
    "        cer = dist / max(len(g), 1)  \n",
    "        total_cer += cer\n",
    "        total_count += 1\n",
    "\n",
    "    return total_cer / max(1, total_count)\n",
    "\n",
    "\n",
    "def test_model(model, test_loader, device, itos, pad_id, bos_id, eos_id):\n",
    "    model_device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    total_cer, total_count = 0.0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            src = batch[\"rus\"].to(model_device)\n",
    "            trg = batch[\"eng\"].to(model_device)\n",
    "\n",
    "            output = greedy_decode(model, src, bos_id, eos_id, model_device)\n",
    "\n",
    "            cer = character_error_rate(\n",
    "                output.cpu().tolist(),\n",
    "                trg[:, 1:].cpu().tolist(),\n",
    "                itos, pad_id, bos_id, eos_id\n",
    "            )\n",
    "\n",
    "            total_cer += cer * src.size(0)\n",
    "            total_count += src.size(0)\n",
    "\n",
    "    return total_cer / max(1, total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb5f8e",
   "metadata": {},
   "source": [
    "### Loading/Saving the Model\n",
    "\n",
    "Training this model was rather compute heavy for my standards and my Mac was not up to the task. Instead I trained it on my 1660 ti GPU, and it actually performed suprisingly well. I measured the difference between the training time of a single epoch and it was 4 vs. 40 minutes. The code to load or save models is here.\n",
    "\n",
    "I used embedding sizes of 128 and hidden layer dimensions of 512. These were largely chosen arbirtrarily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "018f806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and loss history loaded!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model_and_loss_history(model, train_loss, val_loss):\n",
    "    torch.save(model.state_dict(), 'model.pth')\n",
    "    loss_history = {\n",
    "        'train_loss': train_loss,   \n",
    "        'val_loss': val_loss        \n",
    "    }\n",
    "\n",
    "    with open('loss_history.pkl', 'wb') as f:\n",
    "        pickle.dump(loss_history, f)\n",
    "\n",
    "def load_model_and_loss_history(model_path='model.pth', loss_history_path='loss_history.pkl', device= \"cpu\"):\n",
    "   \n",
    "    model = Seq2SeqModel(\n",
    "        src_vocab_size=len(russian_vocab),\n",
    "        trg_vocab_size=len(english_vocab),\n",
    "        emb_dim=128,\n",
    "        hidden_dim=512,\n",
    "        padding_idx=PAD_ID\n",
    "    )\n",
    "\n",
    "    state = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state, strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with open(loss_history_path, 'rb') as f:\n",
    "        loss_history = pickle.load(f)\n",
    "\n",
    "    return model, loss_history\n",
    "\n",
    "\n",
    "new_model, loss_history = load_model_and_loss_history()\n",
    "print(\"Model and loss history loaded!\")\n",
    "\n",
    "plt.plot(loss_history['train_loss'], label='Train Loss')\n",
    "plt.plot(loss_history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43826344",
   "metadata": {},
   "source": [
    "Here is the code I actually used to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b58b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "new_model = Seq2SeqModel(\n",
    "    src_vocab_size=len(russian_vocab),\n",
    "    trg_vocab_size=len(english_vocab),\n",
    "    emb_dim=128,\n",
    "    hidden_dim=512,\n",
    "    padding_idx=PAD_ID\n",
    ").to(device)\n",
    "optimizer = optim.Adam(new_model.parameters(), lr=0.001)\n",
    "new_model.to(device) \n",
    "train_loss, val_loss = train(new_model, train_loader, val_loader, PAD_ID, optimizer, device, num_epochs=10 )\n",
    "save_model_and_loss_history(new_model, train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbfd7f4",
   "metadata": {},
   "source": [
    "### Performance Review\n",
    "\n",
    "Using the testing function we defined earlier we can see that the model has a CER of 19.5%. This intuitively means that for a string with 10 characters there are on average about 2 fixes that we can make.\n",
    "\n",
    "This isn't great. For a task like transliteration, even from differenly sounding languages, we are learning a mapping that is nearly one-to-one. There are of course nuances involved, but we should really be in single digits for our CER. As the intention of this project was to simply see how Seq2Seq are implemented and not create the best transliteration model I will not be trying to optimize the model architecture or hyperparameters. In all honestsy, after playing around with different inputs I couldn't see why the model performance was so low, in my eyes it was actually pretty good to use. I will however note a couple of things that I thing could help for this task:\n",
    "- The low hanging fruit is that we can up the parameter count and regularize accordingly, but that's lazy and inneficient\n",
    "- I suspect that we don't actually need to use RNN's in the decoder, I think that the context window for characters is really small and instead a 1D CNN could be more efficient and effective\n",
    "- The data does include weights of how likely a transliteration is. So far we ignored this, but I think modifying the loss function to include those weights could be simple and helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ed8a61cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1945)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(test_model(new_model, test_loader, device, english_itos, PAD_ID, BOS_ID, EOS_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336aaeec",
   "metadata": {},
   "source": [
    "### Using the Model\n",
    "\n",
    "The code below lets us use the model on our wanted input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0d5ea587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transliterate(russian_text, model, device=device):\n",
    "    \"\"\"Transliterate a Russian string to English using the trained model.\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    normalized_text = unicodedata.normalize(\"NFC\", russian_text.lower())\n",
    "    encoded_text = encode(normalized_text, russian_stoi)\n",
    "\n",
    "    cpu_src = torch.tensor([encoded_text], dtype=torch.long)            \n",
    "    input_tensor = cpu_src.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = greedy_decode(model, input_tensor, BOS_ID, EOS_ID, device)\n",
    "\n",
    "    if isinstance(output, torch.Tensor):\n",
    "        out_ids = output[0].detach().cpu().tolist()\n",
    "    else:\n",
    "        out_ids = list(output[0])\n",
    "\n",
    "    transliteration = decode(out_ids, english_itos)\n",
    "    transliteration = transliteration.replace(\"<eos>\", \"\").strip()\n",
    "\n",
    "    print(f\"Russian: {russian_text}\")\n",
    "    print(f\"Transliteration: {transliteration}\")\n",
    "    print(\"=\" * 50)\n",
    "    return transliteration\n",
    "\n",
    "\n",
    "def test_transliterations(words, model, device=device):\n",
    "    for w in words:\n",
    "        transliterate(w, model, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b1d75",
   "metadata": {},
   "source": [
    "### Example Usage\n",
    "\n",
    "- Russian: Спасибо, что прочитали этот блокнот. Ваш друг, Артём.\n",
    "- English: Thank you for reading this notebook. Your friend, Artem\n",
    "- Google Translate's Transliteration: Spasibo, chto prochitali etot bloknot. Vash drug, Artom.\n",
    "- Our Transliteration: Spacibo, tchtho prochitali etoth bloknoth. Uash drooh, Arthiom.\n",
    "\n",
    "I will say that I am suprised at how poor Google Translate's transliteration is. I would think that this task is something that would be trivial for them. For example, my model is actually arguably closer to the transliteration of the word friend which should be \"droog\" as well as my first name which should be \"Artyom\". Overall, my model is ok and I can see that it is very close to the proper conversion, it has learned to use the letter \"h\" too much for some reason. This could be a fun project to come back to and try to get a more accurate performance.\n",
    "\n",
    "Спасибо, что прочитали этот блокнот. Ваш друг, Артём."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4491bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Russian: спасибо\n",
      "Transliteration: spacibo\n",
      "==================================================\n",
      "Russian: что\n",
      "Transliteration: tchtho\n",
      "==================================================\n",
      "Russian: прочитали\n",
      "Transliteration: prochitali\n",
      "==================================================\n",
      "Russian: этот\n",
      "Transliteration: etoth\n",
      "==================================================\n",
      "Russian: блокнот\n",
      "Transliteration: bloknoth\n",
      "==================================================\n",
      "Russian: ваш\n",
      "Transliteration: uash\n",
      "==================================================\n",
      "Russian: друг\n",
      "Transliteration: drooh\n",
      "==================================================\n",
      "Russian: артём\n",
      "Transliteration: arthiom\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "test_transliterations([\"спасибо\", \"что\", \"прочитали\", \"этот\", \"блокнот\", \"ваш\", \"друг\", \"артём\"], model=new_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
